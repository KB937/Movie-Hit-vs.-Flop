{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Error Analysis\n",
                "\n",
                "This notebook dives into the errors made by our best model (Logistic Regression). We will identify False Positives (Flops predicted as Hits) and False Negatives (Hits predicted as Flops) and inspect specific movies.\n",
                "\n",
                "## Goals\n",
                "1. Load Data & Model\n",
                "2. Generate Predictions\n",
                "3. Identify & Visualize Errors\n",
                "4. Inspect Specific Movie Titles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.8.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
                        "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded data shape: (2596, 49)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.8.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
                        "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
                        "  warnings.warn(\n",
                        "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.8.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
                        "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "# Load processed data\n",
                "df_processed = pd.read_csv('../data/processed/train_processed.csv')\n",
                "\n",
                "# Load Model\n",
                "pipeline = joblib.load('../models/movie_hit_flop_pipeline.joblib')\n",
                "\n",
                "print(f\"Loaded data shape: {df_processed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'LogisticRegression' object has no attribute 'multi_class'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m y_true = df_processed[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].map({\u001b[33m'\u001b[39m\u001b[33mHit\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFlop\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m}) \u001b[38;5;66;03m# 1=Hit, 0=Flop\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Predict Probabilities\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m y_proba = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Apply Best Threshold (from training report ~0.31)\u001b[39;00m\n\u001b[32m     14\u001b[39m threshold = \u001b[32m0.31\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:905\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    904\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    908\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1457\u001b[39m, in \u001b[36mLogisticRegression.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1431\u001b[39m \u001b[33;03mProbability estimates.\u001b[39;00m\n\u001b[32m   1432\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1453\u001b[39m \u001b[33;03m    where classes are ordered as they are in ``self.classes_``.\u001b[39;00m\n\u001b[32m   1454\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1455\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1457\u001b[39m ovr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmulti_class\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33movr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1458\u001b[39m     \u001b[38;5;28mself\u001b[39m.multi_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdeprecated\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1459\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.classes_.size <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.solver == \u001b[33m\"\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1460\u001b[39m )\n\u001b[32m   1461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[32m   1462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._predict_proba_lr(X)\n",
                        "\u001b[31mAttributeError\u001b[39m: 'LogisticRegression' object has no attribute 'multi_class'"
                    ]
                }
            ],
            "source": [
                "# Prepare features (drop non-features)\n",
                "drop_cols = ['id', 'label', 'release_date'] \n",
                "X = df_processed.drop(columns=[c for c in drop_cols if c in df_processed.columns])\n",
                "X = X.select_dtypes(include=[np.number])\n",
                "X = X.fillna(X.mean())\n",
                "\n",
                "# Get True Labels\n",
                "y_true = df_processed['label'].map({'Hit': 1, 'Flop': 0}) # 1=Hit, 0=Flop\n",
                "\n",
                "# Predict Probabilities\n",
                "y_proba = pipeline.predict_proba(X)[:, 1]\n",
                "\n",
                "# Apply Best Threshold (from training report ~0.31)\n",
                "threshold = 0.31\n",
                "y_pred = (y_proba >= threshold).astype(int)\n",
                "\n",
                "# Add to dataframe\n",
                "df_processed['prob_hit'] = y_proba\n",
                "df_processed['pred_label'] = y_pred\n",
                "df_processed['true_label'] = y_true\n",
                "\n",
                "# Error Categorization\n",
                "def categorize_error(row):\n",
                "    if row['true_label'] == 1 and row['pred_label'] == 1:\n",
                "        return 'TP' # True Hit\n",
                "    elif row['true_label'] == 0 and row['pred_label'] == 0:\n",
                "        return 'TN' # True Flop\n",
                "    elif row['true_label'] == 0 and row['pred_label'] == 1:\n",
                "        return 'FP' # Predicted Hit but was Flop (Costly Mistake)\n",
                "    elif row['true_label'] == 1 and row['pred_label'] == 0:\n",
                "        return 'FN' # Predicted Flop but was Hit (Missed Opportunity)\n",
                "\n",
                "df_processed['error_type'] = df_processed.apply(categorize_error, axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Analyze Errors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8, 5))\n",
                "sns.countplot(x='error_type', data=df_processed, order=['TP', 'TN', 'FP', 'FN'], palette='coolwarm')\n",
                "plt.title('Count of Prediction Types')\n",
                "plt.show()\n",
                "\n",
                "print(df_processed['error_type'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Inspect Specific Errors\n",
                "\n",
                "### False Positives (Risky Bets)\n",
                "Movies we predicted would be HITS, but were actually FLOPS. These would lose money."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_to_show = ['budget', 'revenue', 'prob_hit', 'error_type']\n",
                "\n",
                "# Top False Positives (Highest probability of being a Hit, but was a Flop)\n",
                "fp_df = df_processed[df_processed['error_type'] == 'FP'].sort_values('prob_hit', ascending=False)\n",
                "print(\"Top 10 False Positives (Predicted Hit, Actual Flop):\")\n",
                "fp_df[cols_to_show].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### False Negatives (Missed Gems)\n",
                "Movies we predicted would be FLOPS, but were actually HITS."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top False Negatives (Lowest probability of being a Hit, but was a Hit)\n",
                "fn_df = df_processed[df_processed['error_type'] == 'FN'].sort_values('prob_hit', ascending=True)\n",
                "print(\"Top 10 False Negatives (Predicted Flop, Actual Hit):\")\n",
                "fn_df[cols_to_show].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Budget Distribution by Error Type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='error_type', y='budget', data=df_processed, order=['TP', 'TN', 'FP', 'FN'], palette='viridis')\n",
                "plt.title('Budget Distribution by Prediction Outcome')\n",
                "plt.yscale('log')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
